# takes in a request with project name and artifact to be generated
# gets the prompt template for the artifact
# gets context for the prompt 
# create the new prompt
# sends the prompt to external LLM service for completion
# stores the generate content in the project's store 